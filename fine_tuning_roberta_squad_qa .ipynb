{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7657266,"sourceType":"datasetVersion","datasetId":4464546}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#load all libraries\nimport requests\nimport json\nimport torch\nimport torch.nn as nn\nimport os\nfrom tqdm import tqdm\nfrom transformers import BertModel, BertTokenizerFast, AdamW, AutoTokenizer, AutoModelForQuestionAnswering, BertTokenizer, BertForQuestionAnswering\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ExponentialLR\nimport matplotlib.pyplot as plt\nfrom transformers import RobertaConfig, RobertaModel, RobertaTokenizerFast\n\n# # Initializing a RoBERTa configuration\n# configuration = RobertaConfig()\n\n# # Initializing a model (with random weights) from the configuration\n# model = RobertaModel(configuration)\n\n# # Accessing the model configuration\n# configuration = model.config","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-22T12:25:41.974772Z","iopub.execute_input":"2024-02-22T12:25:41.975133Z","iopub.status.idle":"2024-02-22T12:25:41.981775Z","shell.execute_reply.started":"2024-02-22T12:25:41.975106Z","shell.execute_reply":"2024-02-22T12:25:41.980778Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = 'roberta-base'","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:41.983699Z","iopub.execute_input":"2024-02-22T12:25:41.984011Z","iopub.status.idle":"2024-02-22T12:25:41.993593Z","shell.execute_reply.started":"2024-02-22T12:25:41.983987Z","shell.execute_reply":"2024-02-22T12:25:41.992706Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:41.994706Z","iopub.execute_input":"2024-02-22T12:25:41.995036Z","iopub.status.idle":"2024-02-22T12:25:44.195455Z","shell.execute_reply.started":"2024-02-22T12:25:41.995004Z","shell.execute_reply":"2024-02-22T12:25:44.194300Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"File 'train-v2.0.json' already there; not retrieving.\n\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"File 'dev-v2.0.json' already there; not retrieving.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"num_questions = 0\nnum_posible = 0\nnum_imposible = 0","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:44.198981Z","iopub.execute_input":"2024-02-22T12:25:44.199367Z","iopub.status.idle":"2024-02-22T12:25:44.204648Z","shell.execute_reply.started":"2024-02-22T12:25:44.199335Z","shell.execute_reply":"2024-02-22T12:25:44.203608Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#note: below code will only return questions wich have answers (i.e. not the ones flagged as imposible to answer)\ndef get_data(path):  \n    #read each file and retrieve the contexts, qustions and answers\n  with open(path, 'rb') as f:\n    raw_data = json.load(f)\n\n  contexts = []\n  questions = []\n  answers = []\n  num_q = 0\n  num_pos = 0\n  num_imp = 0\n\n  for group in raw_data['data']:\n    for paragraph in group['paragraphs']:\n      context = paragraph['context']\n      for qa in paragraph['qas']:\n        question = qa['question']\n        num_q  = num_q  +1\n        if qa['is_impossible'] == True:\n            num_imp = num_imp +1\n        else:\n            num_pos = num_pos +1\n        for answer in qa['answers']:\n          contexts.append(context.lower())\n          questions.append(question.lower())\n          answers.append(answer)\n\n  return num_q, num_pos, num_imp, contexts, questions, answers","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:44.206155Z","iopub.execute_input":"2024-02-22T12:25:44.207982Z","iopub.status.idle":"2024-02-22T12:25:44.217409Z","shell.execute_reply.started":"2024-02-22T12:25:44.207945Z","shell.execute_reply":"2024-02-22T12:25:44.216492Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"num_q, num_pos, num_imp, train_contexts, train_questions, train_answers = get_data('./train-v2.0.json')\nnum_questions  = num_q\nnum_posible = num_pos\nnum_imposible  = num_imp","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:44.218588Z","iopub.execute_input":"2024-02-22T12:25:44.218945Z","iopub.status.idle":"2024-02-22T12:25:46.170353Z","shell.execute_reply.started":"2024-02-22T12:25:44.218913Z","shell.execute_reply":"2024-02-22T12:25:46.169588Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"num_q, num_pos, num_imp, valid_contexts, valid_questions, valid_answers = get_data('./dev-v2.0.json')\nnum_questions  = num_questions + num_q\nnum_posible = num_posible + num_pos\nnum_imposible = num_imposible  + num_imp\n\nprint(f\"Total number of questions: {num_questions}\")\nprint(f\"Total number of Answerable questions: {num_posible}\")\nprint(f\"Total number of impossible questions: {num_imposible}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:46.171454Z","iopub.execute_input":"2024-02-22T12:25:46.171729Z","iopub.status.idle":"2024-02-22T12:25:46.366882Z","shell.execute_reply.started":"2024-02-22T12:25:46.171707Z","shell.execute_reply":"2024-02-22T12:25:46.365932Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Total number of questions: 142192\nTotal number of Answerable questions: 92749\nTotal number of impossible questions: 49443\n","output_type":"stream"}]},{"cell_type":"code","source":"def add_answer_end(answers, contexts):\n  for answer, context in zip(answers, contexts):\n    answer['text'] = answer['text'].lower()\n    answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n\nadd_answer_end(train_answers, train_contexts)\nadd_answer_end(valid_answers, valid_contexts)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:46.368199Z","iopub.execute_input":"2024-02-22T12:25:46.368575Z","iopub.status.idle":"2024-02-22T12:25:46.462321Z","shell.execute_reply.started":"2024-02-22T12:25:46.368526Z","shell.execute_reply":"2024-02-22T12:25:46.461587Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(f\"Context: {train_contexts[0]}\")\nprint(f\"Question: {train_questions[0]}\")\nprint(f\"Answer: {train_answers[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:46.465412Z","iopub.execute_input":"2024-02-22T12:25:46.465765Z","iopub.status.idle":"2024-02-22T12:25:46.470733Z","shell.execute_reply.started":"2024-02-22T12:25:46.465740Z","shell.execute_reply":"2024-02-22T12:25:46.469823Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Context: beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ bee-yon-say) (born september 4, 1981) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r&b girl-group destiny's child. managed by her father, mathew knowles, the group became one of the world's best-selling girl groups of all time. their hiatus saw the release of beyoncé's debut album, dangerously in love (2003), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number-one singles \"crazy in love\" and \"baby boy\".\nQuestion: when did beyonce start becoming popular?\nAnswer: {'text': 'in the late 1990s', 'answer_start': 269, 'answer_end': 286}\n","output_type":"stream"}]},{"cell_type":"code","source":"test_rec = 30\nprint(f\"Context: {valid_contexts[test_rec]}\")\nprint(f\"Question: {valid_questions[test_rec]}\")\nprint(f\"Answer: {valid_answers[test_rec]}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:46.471824Z","iopub.execute_input":"2024-02-22T12:25:46.472093Z","iopub.status.idle":"2024-02-22T12:25:46.486363Z","shell.execute_reply.started":"2024-02-22T12:25:46.472070Z","shell.execute_reply":"2024-02-22T12:25:46.485550Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Context: the english name \"normans\" comes from the french words normans/normanz, plural of normant, modern french normand, which is itself borrowed from old low franconian nortmann \"northman\" or directly from old norse norðmaðr, latinized variously as nortmannus, normannus, or nordmannus (recorded in medieval latin, 9th century) to mean \"norseman, viking\".\nQuestion: what is the original meaning of the word norman?\nAnswer: {'text': 'norseman, viking', 'answer_start': 331, 'answer_end': 347}\n","output_type":"stream"}]},{"cell_type":"code","source":"MAX_LENGTH = 250  ","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:46.487473Z","iopub.execute_input":"2024-02-22T12:25:46.487826Z","iopub.status.idle":"2024-02-22T12:25:46.495721Z","shell.execute_reply.started":"2024-02-22T12:25:46.487796Z","shell.execute_reply":"2024-02-22T12:25:46.494978Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\ntokenizerFast = RobertaTokenizerFast.from_pretrained(MODEL_PATH)\n\ntrain_encodings_fast = tokenizerFast(train_questions, train_contexts,  max_length = MAX_LENGTH, truncation=True, padding=True)\nvalid_encodings_fast = tokenizerFast(valid_questions,valid_contexts,  max_length = MAX_LENGTH, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:25:46.496816Z","iopub.execute_input":"2024-02-22T12:25:46.497126Z","iopub.status.idle":"2024-02-22T12:26:16.923411Z","shell.execute_reply.started":"2024-02-22T12:25:46.497103Z","shell.execute_reply":"2024-02-22T12:26:16.922365Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 250  ","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:26:16.924747Z","iopub.execute_input":"2024-02-22T12:26:16.925109Z","iopub.status.idle":"2024-02-22T12:26:16.929658Z","shell.execute_reply.started":"2024-02-22T12:26:16.925077Z","shell.execute_reply":"2024-02-22T12:26:16.928702Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def ret_Answer_start_and_end_train(idx):\n    ret_start = 0\n    ret_end = 0\n    answer_encoding_fast = tokenizerFast(train_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n    for a in range( len(train_encodings_fast['input_ids'][idx]) -  len(answer_encoding_fast['input_ids']) ): #len(train_encodings_fast['input_ids'][0])):\n        match = True\n        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n            \n            if (answer_encoding_fast['input_ids'][i] != train_encodings_fast['input_ids'][idx][a + i]):\n                match = False\n                break\n        if match:\n            ret_start = a+1\n            ret_end = a+i+1\n            break\n    return(ret_start, ret_end)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:26:16.930718Z","iopub.execute_input":"2024-02-22T12:26:16.930959Z","iopub.status.idle":"2024-02-22T12:26:16.942570Z","shell.execute_reply.started":"2024-02-22T12:26:16.930938Z","shell.execute_reply":"2024-02-22T12:26:16.941724Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"test_rec=92\n\nz,x = ret_Answer_start_and_end_train(test_rec)\nprint(z, x)\n\npredict_answer_tokens = train_encodings_fast.input_ids[test_rec][z : x]\nprint(tokenizerFast.decode(predict_answer_tokens))\nprint(train_answers[test_rec]['text'])\nprint(tokenizerFast.decode(train_encodings_fast['input_ids'][test_rec]))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:26:16.943662Z","iopub.execute_input":"2024-02-22T12:26:16.943950Z","iopub.status.idle":"2024-02-22T12:26:16.957899Z","shell.execute_reply.started":"2024-02-22T12:26:16.943927Z","shell.execute_reply":"2024-02-22T12:26:16.957028Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"0 0\n\nsplit with luckett and rober\n<s>what event caused beyonce's depression?</s></s>letoya luckett and roberson became unhappy with mathew's managing of the band and eventually were replaced by farrah franklin and michelle williams. beyoncé experienced depression following the split with luckett and roberson after being publicly blamed by the media, critics, and blogs for its cause. her long-standing boyfriend left her at this time. the depression was so severe it lasted for a couple of years, during which she occasionally kept herself in her bedroom for days and refused to eat anything. beyoncé stated that she struggled to speak about her depression because destiny's child had just won their first grammy award and she feared no one would take her seriously. beyoncé would later speak of her mother as the person who helped her fight it. franklin was dismissed, leaving just beyoncé, rowland, and williams.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","output_type":"stream"}]},{"cell_type":"code","source":"def ret_Answer_start_and_end_valid(idx):\n    ret_start = 0\n    ret_end = 0\n    answer_encoding_fast = tokenizerFast(valid_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n    for a in range( len(valid_encodings_fast['input_ids'][idx])  -  len(answer_encoding_fast['input_ids'])   ): #len(train_encodings_fast['input_ids'][0])):\n        match = True\n        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n            if (answer_encoding_fast['input_ids'][i] != valid_encodings_fast['input_ids'][idx][a + i]):\n                match = False\n                break\n        if match:\n            ret_start = a+1\n            ret_end = a+i+1\n            break\n    return(ret_start, ret_end)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:26:16.958908Z","iopub.execute_input":"2024-02-22T12:26:16.959211Z","iopub.status.idle":"2024-02-22T12:26:16.969176Z","shell.execute_reply.started":"2024-02-22T12:26:16.959188Z","shell.execute_reply":"2024-02-22T12:26:16.968382Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def new_func():\n    start_positions = []\n    end_positions = []\n    ctr = 0\n    for h in range(len(train_encodings_fast['input_ids'])):\n    #print(h)\n        s, e = ret_Answer_start_and_end_train(h)\n        start_positions.append(s)\n        end_positions.append(e)\n        if s==0:\n            ctr = ctr + 1\n\n    \n    train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n    print(ctr)\n\nnew_func()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:26:16.970188Z","iopub.execute_input":"2024-02-22T12:26:16.970444Z","iopub.status.idle":"2024-02-22T12:27:04.914063Z","shell.execute_reply.started":"2024-02-22T12:26:16.970422Z","shell.execute_reply":"2024-02-22T12:27:04.913139Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"80360\n","output_type":"stream"}]},{"cell_type":"code","source":"start_positions = []\nend_positions = []\nctr = 0\nfor h in range(len(valid_encodings_fast['input_ids']) ):\n    #print(h)\n    s, e = ret_Answer_start_and_end_valid(h)\n    start_positions.append(s)\n    end_positions.append(e)\n    if s==0:\n        ctr = ctr + 1\n\n    \nvalid_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\nprint(ctr)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:04.915395Z","iopub.execute_input":"2024-02-22T12:27:04.916198Z","iopub.status.idle":"2024-02-22T12:27:16.615711Z","shell.execute_reply.started":"2024-02-22T12:27:04.916162Z","shell.execute_reply":"2024-02-22T12:27:16.614738Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"18954\n","output_type":"stream"}]},{"cell_type":"code","source":"\nanswer_start_index = 75\nanswer_end_index = 79\n\npredict_answer_tokens = train_encodings_fast.input_ids[0][answer_start_index : answer_end_index]\ntokenizerFast.decode(predict_answer_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:16.617209Z","iopub.execute_input":"2024-02-22T12:27:16.617606Z","iopub.status.idle":"2024-02-22T12:27:16.624621Z","shell.execute_reply.started":"2024-02-22T12:27:16.617572Z","shell.execute_reply":"2024-02-22T12:27:16.623714Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"' she performed in various'"},"metadata":{}}]},{"cell_type":"code","source":"class InputDataset(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n    def __getitem__(self, i):\n        return {\n            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n#             'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n        }\n    def __len__(self):\n        return len(self.encodings['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:16.626032Z","iopub.execute_input":"2024-02-22T12:27:16.626793Z","iopub.status.idle":"2024-02-22T12:27:16.633948Z","shell.execute_reply.started":"2024-02-22T12:27:16.626760Z","shell.execute_reply":"2024-02-22T12:27:16.633093Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"train_dataset = InputDataset(train_encodings_fast)\nvalid_dataset = InputDataset(valid_encodings_fast)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:16.635115Z","iopub.execute_input":"2024-02-22T12:27:16.635454Z","iopub.status.idle":"2024-02-22T12:27:16.649240Z","shell.execute_reply.started":"2024-02-22T12:27:16.635424Z","shell.execute_reply":"2024-02-22T12:27:16.648517Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nvalid_data_loader = DataLoader(valid_dataset, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:16.650257Z","iopub.execute_input":"2024-02-22T12:27:16.650558Z","iopub.status.idle":"2024-02-22T12:27:20.137778Z","shell.execute_reply.started":"2024-02-22T12:27:16.650515Z","shell.execute_reply":"2024-02-22T12:27:20.136717Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"bert_model = RobertaModel.from_pretrained(MODEL_PATH)  #MODEL_PATH = \"bert-base-uncased\"\n\nclass QAModel(nn.Module):\n    def __init__(self):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.drop_out = nn.Dropout(0.1)\n        self.l1 = nn.Linear(768 * 2, 768 * 2)\n        self.l2 = nn.Linear(768 * 2, 2)\n        self.linear_relu_stack = nn.Sequential(\n            self.drop_out,\n            self.l1,\n            nn.LeakyReLU(),\n            self.l2 \n        )\n        \n    def forward(self, input_ids, attention_mask):\n        model_output = self.bert(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n#         model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n        hidden_states = model_output[2]\n        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)  # taking Start logits from last BERT layer, End Logits from third to last layer\n        logits = self.linear_relu_stack(out)\n        \n        start_logits, end_logits = logits.split(1, dim=-1)\n        \n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n\n        return start_logits, end_logits","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:20.139102Z","iopub.execute_input":"2024-02-22T12:27:20.139376Z","iopub.status.idle":"2024-02-22T12:27:20.803803Z","shell.execute_reply.started":"2024-02-22T12:27:20.139353Z","shell.execute_reply":"2024-02-22T12:27:20.802869Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# my function to manually calculate Cross Entropy Loss\ndef loss_fn(start_logits, end_logits, start_positions, end_positions):\n    loss_fct = nn.CrossEntropyLoss()\n    start_loss = loss_fct(start_logits, start_positions)\n    end_loss = loss_fct(end_logits, end_positions)\n    total_loss = (start_loss + end_loss)/2\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:20.808855Z","iopub.execute_input":"2024-02-22T12:27:20.809141Z","iopub.status.idle":"2024-02-22T12:27:20.814275Z","shell.execute_reply.started":"2024-02-22T12:27:20.809117Z","shell.execute_reply":"2024-02-22T12:27:20.813296Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"\n\ndef focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n    \n\n    smax = nn.Softmax(dim=1)\n    probs_start = smax(start_logits)\n    inv_probs_start = 1 - probs_start\n    probs_end = smax(end_logits)\n    inv_probs_end = 1 - probs_end\n\n    lsmax = nn.LogSoftmax(dim=1)\n    log_probs_start = lsmax(start_logits)\n    log_probs_end = lsmax(end_logits)\n    \n    nll = nn.NLLLoss()\n    \n    fl_start = nll(torch.pow(inv_probs_start, gamma)* log_probs_start, start_positions)\n    fl_end = nll(torch.pow(inv_probs_end, gamma)*log_probs_end, end_positions)\n\n    return ((fl_start + fl_end)/2)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:20.815451Z","iopub.execute_input":"2024-02-22T12:27:20.815807Z","iopub.status.idle":"2024-02-22T12:27:20.825847Z","shell.execute_reply.started":"2024-02-22T12:27:20.815775Z","shell.execute_reply":"2024-02-22T12:27:20.825003Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, dataloader, epoch):\n    model = model.train()\n    losses = []\n    acc = []\n    ctr = 0\n    batch_tracker = 0\n    for batch in tqdm(dataloader, desc = 'Running Epoch '):\n        optim.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n#         token_type_ids = batch['token_type_ids'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        out_start, out_end = model(input_ids=input_ids, \n                attention_mask=attention_mask,)\n#                 token_type_ids=token_type_ids)\n        #loss = loss_fn(out_start, out_end, start_positions, end_positions)  #\n        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions,1) \n        losses.append(loss.item())\n        loss.backward()\n        optim.step()\n        \n        start_pred = torch.argmax(out_start, dim=1)\n        end_pred = torch.argmax(out_end, dim=1)\n            \n        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n        #ctr = ctr +1\n        #if ctr==50:\n        #    break\n        batch_tracker = batch_tracker + 1\n        if batch_tracker==250 and epoch==1:\n            total_acc.append(sum(acc)/len(acc))\n            loss_avg = sum(losses)/len(losses)\n            total_loss.append(loss_avg)\n            batch_tracker = 0\n            torch.save(model.state_dict(), 'modelelelel.pt')\n    scheduler.step()\n    ret_acc = sum(acc)/len(acc)\n    ret_loss = sum(losses)/len(losses)\n    return(ret_acc, ret_loss)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:29:09.412935Z","iopub.execute_input":"2024-02-22T12:29:09.413678Z","iopub.status.idle":"2024-02-22T12:29:09.424495Z","shell.execute_reply.started":"2024-02-22T12:29:09.413645Z","shell.execute_reply":"2024-02-22T12:29:09.423576Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, dataloader):\n    model = model.eval()\n    losses = []\n    acc = []\n    ctr = 0\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n#             token_type_ids = batch['token_type_ids'].to(device)\n            start_true = batch['start_positions'].to(device)\n            end_true = batch['end_positions'].to(device)\n            \n            out_start, out_end = model(input_ids=input_ids, \n                attention_mask=attention_mask,)\n#                 token_type_ids=token_type_ids)\n            \n            start_pred = torch.argmax(out_start, dim=1)\n            end_pred = torch.argmax(out_end, dim=1)\n            \n            acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n            acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n            #ctr = ctr +1\n            #if ctr==50:\n            #    break\n        ret_acc = sum(acc)/len(acc)\n        ret_loss = 0\n        #ret_loss = sum(losses)/len(losses)\n    return(ret_acc)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:29:10.867008Z","iopub.execute_input":"2024-02-22T12:29:10.867639Z","iopub.status.idle":"2024-02-22T12:29:10.876396Z","shell.execute_reply.started":"2024-02-22T12:29:10.867606Z","shell.execute_reply":"2024-02-22T12:29:10.875507Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:29:15.112016Z","iopub.execute_input":"2024-02-22T12:29:15.112477Z","iopub.status.idle":"2024-02-22T12:29:15.117378Z","shell.execute_reply.started":"2024-02-22T12:29:15.112425Z","shell.execute_reply":"2024-02-22T12:29:15.116424Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"model = QAModel()\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(device)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:29:16.012280Z","iopub.execute_input":"2024-02-22T12:29:16.012952Z","iopub.status.idle":"2024-02-22T12:29:16.048764Z","shell.execute_reply.started":"2024-02-22T12:29:16.012919Z","shell.execute_reply":"2024-02-22T12:29:16.047861Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"QAModel(\n  (bert): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (drop_out): Dropout(p=0.1, inplace=False)\n  (l1): Linear(in_features=1536, out_features=1536, bias=True)\n  (l2): Linear(in_features=1536, out_features=2, bias=True)\n  (linear_relu_stack): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=1536, out_features=1536, bias=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Linear(in_features=1536, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/input/19-02-2023-wagi/modelek.pt'))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:29:18.723102Z","iopub.execute_input":"2024-02-22T12:29:18.723454Z","iopub.status.idle":"2024-02-22T12:29:18.727448Z","shell.execute_reply.started":"2024-02-22T12:29:18.723427Z","shell.execute_reply":"2024-02-22T12:29:18.726559Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\nscheduler = ExponentialLR(optim, gamma=0.9)\ntotal_acc = []\ntotal_loss = []","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:27:21.207654Z","iopub.execute_input":"2024-02-22T12:27:21.208173Z","iopub.status.idle":"2024-02-22T12:27:21.218205Z","shell.execute_reply.started":"2024-02-22T12:27:21.208142Z","shell.execute_reply":"2024-02-22T12:27:21.217431Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1\n\nfor epoch in range(EPOCHS):\n    train_acc, train_loss = train_epoch(model, train_data_loader, epoch+1)\n    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n    val_acc = eval_model(model, valid_data_loader)\n    print(f\"Validation Accuracy: {val_acc}\")\n    \n# val_acc, val_loss = eval_model(model, valid_data_loader)\n# print(f\"Validation Accuracy: {val_acc}   Validation Loss: {val_loss}\")\n  ","metadata":{"execution":{"iopub.status.busy":"2024-02-22T12:29:21.707232Z","iopub.execute_input":"2024-02-22T12:29:21.707822Z","iopub.status.idle":"2024-02-22T13:11:17.947800Z","shell.execute_reply.started":"2024-02-22T12:29:21.707788Z","shell.execute_reply":"2024-02-22T13:11:17.946865Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"Running Epoch : 100%|██████████| 10853/10853 [39:16<00:00,  4.61it/s] \n","output_type":"stream"},{"name":"stdout","text":"Train Accuracy: 0.9383914585839787      Train Loss: 0.16430984554255748\n","output_type":"stream"},{"name":"stderr","text":"Running Evaluation: 100%|██████████| 1269/1269 [02:40<00:00,  7.92it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.9551319936958235\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}