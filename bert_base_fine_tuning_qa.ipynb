{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7776806,"sourceType":"datasetVersion","datasetId":4550449}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#load all libraries\nimport requests\nimport json\nimport torch\nimport torch.nn as nn\nimport os\nfrom tqdm import tqdm\nfrom transformers import BertModel, BertTokenizerFast, AdamW, AutoTokenizer, AutoModelForQuestionAnswering, BertTokenizer, BertForQuestionAnswering\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ExponentialLR\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:02.437076Z","iopub.execute_input":"2024-03-06T16:15:02.437510Z","iopub.status.idle":"2024-03-06T16:15:02.445174Z","shell.execute_reply.started":"2024-03-06T16:15:02.437478Z","shell.execute_reply":"2024-03-06T16:15:02.443990Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = 'bert-base-uncased'\n# MODEL_PATH = 'distilbert-base-uncased'","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:02.446795Z","iopub.execute_input":"2024-03-06T16:15:02.448057Z","iopub.status.idle":"2024-03-06T16:15:02.458790Z","shell.execute_reply.started":"2024-03-06T16:15:02.448026Z","shell.execute_reply":"2024-03-06T16:15:02.457970Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n!wget -nc https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:02.460559Z","iopub.execute_input":"2024-03-06T16:15:02.461190Z","iopub.status.idle":"2024-03-06T16:15:04.830022Z","shell.execute_reply.started":"2024-03-06T16:15:02.461135Z","shell.execute_reply":"2024-03-06T16:15:04.828605Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"File 'train-v2.0.json' already there; not retrieving.\n\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"File 'dev-v2.0.json' already there; not retrieving.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"num_questions = 0\nnum_posible = 0\nnum_imposible = 0","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:04.832138Z","iopub.execute_input":"2024-03-06T16:15:04.832490Z","iopub.status.idle":"2024-03-06T16:15:04.837593Z","shell.execute_reply.started":"2024-03-06T16:15:04.832460Z","shell.execute_reply":"2024-03-06T16:15:04.836600Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"#note: below code will only return questions wich have answers (i.e. not the ones flagged as imposible to answer)\ndef get_data(path):  \n    #read each file and retrieve the contexts, qustions and answers\n  with open(path, 'rb') as f:\n    raw_data = json.load(f)\n\n  contexts = []\n  questions = []\n  answers = []\n  num_q = 0\n  num_pos = 0\n  num_imp = 0\n\n  for group in raw_data['data']:\n    for paragraph in group['paragraphs']:\n      context = paragraph['context']\n      for qa in paragraph['qas']:\n        question = qa['question']\n        num_q  = num_q  +1\n        if qa['is_impossible'] == True:\n            num_imp = num_imp +1\n        else:\n            num_pos = num_pos +1\n        for answer in qa['answers']:\n          contexts.append(context.lower())\n          questions.append(question.lower())\n          answers.append(answer)\n\n  return num_q, num_pos, num_imp, contexts, questions, answers","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:04.840584Z","iopub.execute_input":"2024-03-06T16:15:04.841011Z","iopub.status.idle":"2024-03-06T16:15:04.851748Z","shell.execute_reply.started":"2024-03-06T16:15:04.840973Z","shell.execute_reply":"2024-03-06T16:15:04.850689Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"num_q, num_pos, num_imp, train_contexts, train_questions, train_answers = get_data('./train-v2.0.json')\nnum_questions  = num_q\nnum_posible = num_pos\nnum_imposible  = num_imp","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:04.853090Z","iopub.execute_input":"2024-03-06T16:15:04.853472Z","iopub.status.idle":"2024-03-06T16:15:08.251128Z","shell.execute_reply.started":"2024-03-06T16:15:04.853438Z","shell.execute_reply":"2024-03-06T16:15:08.250245Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"(type(train_questions),\ntype(train_questions),\ntype(train_answers))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.252326Z","iopub.execute_input":"2024-03-06T16:15:08.252663Z","iopub.status.idle":"2024-03-06T16:15:08.258879Z","shell.execute_reply.started":"2024-03-06T16:15:08.252636Z","shell.execute_reply":"2024-03-06T16:15:08.257924Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"(list, list, list)"},"metadata":{}}]},{"cell_type":"code","source":"print(train_questions[0:10])\nprint(train_answers[0:10])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.260163Z","iopub.execute_input":"2024-03-06T16:15:08.260520Z","iopub.status.idle":"2024-03-06T16:15:08.271135Z","shell.execute_reply.started":"2024-03-06T16:15:08.260493Z","shell.execute_reply":"2024-03-06T16:15:08.270149Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"['when did beyonce start becoming popular?', 'what areas did beyonce compete in when she was growing up?', \"when did beyonce leave destiny's child and become a solo singer?\", 'in what city and state did beyonce  grow up? ', 'in which decade did beyonce become famous?', 'in what r&b group was she the lead singer?', 'what album made her a worldwide known artist?', \"who managed the destiny's child group?\", 'when did beyoncé rise to fame?', \"what role did beyoncé have in destiny's child?\"]\n[{'text': 'in the late 1990s', 'answer_start': 269}, {'text': 'singing and dancing', 'answer_start': 207}, {'text': '2003', 'answer_start': 526}, {'text': 'Houston, Texas', 'answer_start': 166}, {'text': 'late 1990s', 'answer_start': 276}, {'text': \"Destiny's Child\", 'answer_start': 320}, {'text': 'Dangerously in Love', 'answer_start': 505}, {'text': 'Mathew Knowles', 'answer_start': 360}, {'text': 'late 1990s', 'answer_start': 276}, {'text': 'lead singer', 'answer_start': 290}]\n","output_type":"stream"}]},{"cell_type":"code","source":"num_q, num_pos, num_imp, valid_contexts, valid_questions, valid_answers = get_data('./dev-v2.0.json')\nnum_questions  = num_questions + num_q\nnum_posible = num_posible + num_pos\nnum_imposible = num_imposible  + num_imp\n\nprint(f\"Total number of questions: {num_questions}\")\nprint(f\"Total number of Answerable questions: {num_posible}\")\nprint(f\"Total number of impossible questions: {num_imposible}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.272270Z","iopub.execute_input":"2024-03-06T16:15:08.272516Z","iopub.status.idle":"2024-03-06T16:15:08.481123Z","shell.execute_reply.started":"2024-03-06T16:15:08.272494Z","shell.execute_reply":"2024-03-06T16:15:08.480120Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Total number of questions: 142192\nTotal number of Answerable questions: 92749\nTotal number of impossible questions: 49443\n","output_type":"stream"}]},{"cell_type":"code","source":"print(valid_questions[0:10])\nprint(valid_answers[0:10])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.484672Z","iopub.execute_input":"2024-03-06T16:15:08.484964Z","iopub.status.idle":"2024-03-06T16:15:08.489975Z","shell.execute_reply.started":"2024-03-06T16:15:08.484940Z","shell.execute_reply":"2024-03-06T16:15:08.488884Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"['in what country is normandy located?', 'in what country is normandy located?', 'in what country is normandy located?', 'in what country is normandy located?', 'when were the normans in normandy?', 'when were the normans in normandy?', 'when were the normans in normandy?', 'when were the normans in normandy?', 'from which countries did the norse originate?', 'from which countries did the norse originate?']\n[{'text': 'France', 'answer_start': 159}, {'text': 'France', 'answer_start': 159}, {'text': 'France', 'answer_start': 159}, {'text': 'France', 'answer_start': 159}, {'text': '10th and 11th centuries', 'answer_start': 94}, {'text': 'in the 10th and 11th centuries', 'answer_start': 87}, {'text': '10th and 11th centuries', 'answer_start': 94}, {'text': '10th and 11th centuries', 'answer_start': 94}, {'text': 'Denmark, Iceland and Norway', 'answer_start': 256}, {'text': 'Denmark, Iceland and Norway', 'answer_start': 256}]\n","output_type":"stream"}]},{"cell_type":"code","source":"def add_answer_end(answers, contexts):\n  for answer, context in zip(answers, contexts):\n    answer['text'] = answer['text'].lower()\n    answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n\nadd_answer_end(train_answers, train_contexts)\nadd_answer_end(valid_answers, valid_contexts)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.491089Z","iopub.execute_input":"2024-03-06T16:15:08.491345Z","iopub.status.idle":"2024-03-06T16:15:08.597253Z","shell.execute_reply.started":"2024-03-06T16:15:08.491314Z","shell.execute_reply":"2024-03-06T16:15:08.596340Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"print(f\"Context: {train_contexts[0]}\")\nprint(f\"Question: {train_questions[0]}\")\nprint(f\"Answer: {train_answers[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.598499Z","iopub.execute_input":"2024-03-06T16:15:08.598828Z","iopub.status.idle":"2024-03-06T16:15:08.604253Z","shell.execute_reply.started":"2024-03-06T16:15:08.598801Z","shell.execute_reply":"2024-03-06T16:15:08.603268Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Context: beyoncé giselle knowles-carter (/biːˈjɒnseɪ/ bee-yon-say) (born september 4, 1981) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r&b girl-group destiny's child. managed by her father, mathew knowles, the group became one of the world's best-selling girl groups of all time. their hiatus saw the release of beyoncé's debut album, dangerously in love (2003), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number-one singles \"crazy in love\" and \"baby boy\".\nQuestion: when did beyonce start becoming popular?\nAnswer: {'text': 'in the late 1990s', 'answer_start': 269, 'answer_end': 286}\n","output_type":"stream"}]},{"cell_type":"code","source":"test_rec = 30\nprint(f\"Context: {valid_contexts[test_rec]}\")\nprint(f\"Question: {valid_questions[test_rec]}\")\nprint(f\"Answer: {valid_answers[test_rec]}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.606047Z","iopub.execute_input":"2024-03-06T16:15:08.606424Z","iopub.status.idle":"2024-03-06T16:15:08.615584Z","shell.execute_reply.started":"2024-03-06T16:15:08.606390Z","shell.execute_reply":"2024-03-06T16:15:08.614690Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Context: the english name \"normans\" comes from the french words normans/normanz, plural of normant, modern french normand, which is itself borrowed from old low franconian nortmann \"northman\" or directly from old norse norðmaðr, latinized variously as nortmannus, normannus, or nordmannus (recorded in medieval latin, 9th century) to mean \"norseman, viking\".\nQuestion: what is the original meaning of the word norman?\nAnswer: {'text': 'norseman, viking', 'answer_start': 331, 'answer_end': 347}\n","output_type":"stream"}]},{"cell_type":"code","source":"# #Text lengths to contextx\n# token_lens = []\n\n# for txt in train_contexts:\n#     txt = txt.strip()  # remove leading and trailing whitespaces\n#     token_lens.append(len(txt.split(' ')))\n  \n\n# print(max(token_lens))\n\n# plt.hist(token_lens,  bins=20)  # density=False would make counts\n# plt.ylabel('Count')\n# plt.xlabel('Length')\n# plt.title('Distribution of Context Lengths');","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.616810Z","iopub.execute_input":"2024-03-06T16:15:08.617233Z","iopub.status.idle":"2024-03-06T16:15:08.626172Z","shell.execute_reply.started":"2024-03-06T16:15:08.617199Z","shell.execute_reply":"2024-03-06T16:15:08.625131Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# #Test lengths of Questions\n# token_lens2 = []\n\n# for txt in train_questions:\n#     txt = txt.strip()  # remove leading and trailing whitespaces\n#     token_lens2.append(len(txt.split(' ')))\n\n\n# print(max(token_lens2))\n# print(len(token_lens2))\n\n# plt.hist(token_lens2,  bins=20)  # density=False would make counts\n# plt.ylabel('Count')\n# plt.xlabel('Length')\n# plt.title('Distribution of Question Lengths');","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.627489Z","iopub.execute_input":"2024-03-06T16:15:08.628351Z","iopub.status.idle":"2024-03-06T16:15:08.636955Z","shell.execute_reply.started":"2024-03-06T16:15:08.628315Z","shell.execute_reply":"2024-03-06T16:15:08.636152Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"MAX_LENGTH = 250  ","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.637998Z","iopub.execute_input":"2024-03-06T16:15:08.638258Z","iopub.status.idle":"2024-03-06T16:15:08.650925Z","shell.execute_reply.started":"2024-03-06T16:15:08.638235Z","shell.execute_reply":"2024-03-06T16:15:08.649882Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n\ntrain_encodings_fast = tokenizerFast(train_questions, train_contexts,  max_length = MAX_LENGTH, truncation=True, padding=True)\nvalid_encodings_fast = tokenizerFast(valid_questions,valid_contexts,  max_length = MAX_LENGTH, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:08.652182Z","iopub.execute_input":"2024-03-06T16:15:08.653009Z","iopub.status.idle":"2024-03-06T16:15:44.688033Z","shell.execute_reply.started":"2024-03-06T16:15:08.652975Z","shell.execute_reply":"2024-03-06T16:15:44.687103Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"type(train_encodings_fast)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.689488Z","iopub.execute_input":"2024-03-06T16:15:44.689941Z","iopub.status.idle":"2024-03-06T16:15:44.696829Z","shell.execute_reply.started":"2024-03-06T16:15:44.689903Z","shell.execute_reply":"2024-03-06T16:15:44.695827Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"transformers.tokenization_utils_base.BatchEncoding"},"metadata":{}}]},{"cell_type":"code","source":"\nprint(train_encodings_fast.keys())\nprint(valid_encodings_fast.keys())\nprint(len(train_encodings_fast['input_ids']))\nprint(len(train_encodings_fast['input_ids'][0]))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.698389Z","iopub.execute_input":"2024-03-06T16:15:44.698819Z","iopub.status.idle":"2024-03-06T16:15:44.707459Z","shell.execute_reply.started":"2024-03-06T16:15:44.698783Z","shell.execute_reply":"2024-03-06T16:15:44.706519Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n86821\n250\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_encodings_fast['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.708769Z","iopub.execute_input":"2024-03-06T16:15:44.709075Z","iopub.status.idle":"2024-03-06T16:15:44.720300Z","shell.execute_reply.started":"2024-03-06T16:15:44.709049Z","shell.execute_reply":"2024-03-06T16:15:44.719359Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"[101, 2043, 2106, 20773, 2707, 3352, 2759, 1029, 102, 20773, 21025, 19358, 22815, 1011, 5708, 1006, 1013, 12170, 23432, 29715, 3501, 29678, 12325, 29685, 1013, 10506, 1011, 10930, 2078, 1011, 2360, 1007, 1006, 2141, 2244, 1018, 1010, 3261, 1007, 2003, 2019, 2137, 3220, 1010, 6009, 1010, 2501, 3135, 1998, 3883, 1012, 2141, 1998, 2992, 1999, 5395, 1010, 3146, 1010, 2016, 2864, 1999, 2536, 4823, 1998, 5613, 6479, 2004, 1037, 2775, 1010, 1998, 3123, 2000, 4476, 1999, 1996, 2397, 4134, 2004, 2599, 3220, 1997, 1054, 1004, 1038, 2611, 1011, 2177, 10461, 1005, 1055, 2775, 1012, 3266, 2011, 2014, 2269, 1010, 25436, 22815, 1010, 1996, 2177, 2150, 2028, 1997, 1996, 2088, 1005, 1055, 2190, 1011, 4855, 2611, 2967, 1997, 2035, 2051, 1012, 2037, 14221, 2387, 1996, 2713, 1997, 20773, 1005, 1055, 2834, 2201, 1010, 20754, 1999, 2293, 1006, 2494, 1007, 1010, 2029, 2511, 2014, 2004, 1037, 3948, 3063, 4969, 1010, 3687, 2274, 8922, 2982, 1998, 2956, 1996, 4908, 2980, 2531, 2193, 1011, 2028, 3895, 1000, 4689, 1999, 2293, 1000, 1998, 1000, 3336, 2879, 1000, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_answer_encodings_fast = tokenizerFast(train_answers[0]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.721469Z","iopub.execute_input":"2024-03-06T16:15:44.722123Z","iopub.status.idle":"2024-03-06T16:15:44.733609Z","shell.execute_reply.started":"2024-03-06T16:15:44.722095Z","shell.execute_reply":"2024-03-06T16:15:44.732565Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"def ret_Answer_start_and_end_train(idx):\n    ret_start = 0\n    ret_end = 0\n    answer_encoding_fast = tokenizerFast(train_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n    for a in range( len(train_encodings_fast['input_ids'][idx]) -  len(answer_encoding_fast['input_ids']) ): #len(train_encodings_fast['input_ids'][0])):\n        match = True\n        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n            \n            if (answer_encoding_fast['input_ids'][i] != train_encodings_fast['input_ids'][idx][a + i]):\n                match = False\n                break\n        if match:\n            ret_start = a+1\n            ret_end = a+i+1\n            break\n    return(ret_start, ret_end)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.734847Z","iopub.execute_input":"2024-03-06T16:15:44.735190Z","iopub.status.idle":"2024-03-06T16:15:44.744785Z","shell.execute_reply.started":"2024-03-06T16:15:44.735156Z","shell.execute_reply":"2024-03-06T16:15:44.743856Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"test_rec=92\n\nz,x = ret_Answer_start_and_end_train(test_rec)\nprint(z, x)\n\npredict_answer_tokens = train_encodings_fast.input_ids[test_rec][z : x]\nprint(tokenizerFast.decode(predict_answer_tokens))\nprint(train_answers[test_rec]['text'])\nprint(tokenizerFast.decode(train_encodings_fast['input_ids'][test_rec]))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.745955Z","iopub.execute_input":"2024-03-06T16:15:44.746390Z","iopub.status.idle":"2024-03-06T16:15:44.761416Z","shell.execute_reply.started":"2024-03-06T16:15:44.746359Z","shell.execute_reply":"2024-03-06T16:15:44.760394Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"0 0\n\nsplit with luckett and rober\n[CLS] what event caused beyonce's depression? [SEP] letoya luckett and roberson became unhappy with mathew's managing of the band and eventually were replaced by farrah franklin and michelle williams. beyonce experienced depression following the split with luckett and roberson after being publicly blamed by the media, critics, and blogs for its cause. her long - standing boyfriend left her at this time. the depression was so severe it lasted for a couple of years, during which she occasionally kept herself in her bedroom for days and refused to eat anything. beyonce stated that she struggled to speak about her depression because destiny's child had just won their first grammy award and she feared no one would take her seriously. beyonce would later speak of her mother as the person who helped her fight it. franklin was dismissed, leaving just beyonce, rowland, and williams. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_encodings_fast.keys())\nprint(valid_encodings_fast.keys())\nprint(len(train_encodings_fast['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.762712Z","iopub.execute_input":"2024-03-06T16:15:44.763030Z","iopub.status.idle":"2024-03-06T16:15:44.775950Z","shell.execute_reply.started":"2024-03-06T16:15:44.763005Z","shell.execute_reply":"2024-03-06T16:15:44.774952Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n86821\n","output_type":"stream"}]},{"cell_type":"code","source":"def new_func():\n    start_positions = []\n    end_positions = []\n    ctr = 0\n    for h in range(len(train_encodings_fast['input_ids'])):\n    #print(h)\n        s, e = ret_Answer_start_and_end_train(h)\n        start_positions.append(s)\n        end_positions.append(e)\n        if s==0:\n            ctr = ctr + 1\n\n    \n    train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\n    print(ctr)\n\nnew_func()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:15:44.782237Z","iopub.execute_input":"2024-03-06T16:15:44.782538Z","iopub.status.idle":"2024-03-06T16:16:09.352475Z","shell.execute_reply.started":"2024-03-06T16:15:44.782513Z","shell.execute_reply":"2024-03-06T16:16:09.351075Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"1190\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_encodings_fast.keys())\nprint(valid_encodings_fast.keys())\nprint(len(train_encodings_fast['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:09.353894Z","iopub.execute_input":"2024-03-06T16:16:09.354312Z","iopub.status.idle":"2024-03-06T16:16:09.360259Z","shell.execute_reply.started":"2024-03-06T16:16:09.354281Z","shell.execute_reply":"2024-03-06T16:16:09.359249Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n86821\n","output_type":"stream"}]},{"cell_type":"code","source":"test_rec = 1\nprint(train_encodings_fast['start_positions'][test_rec])\nprint(train_encodings_fast['end_positions'][test_rec])\npredict_answer_tokens = train_encodings_fast.input_ids[test_rec][train_encodings_fast['start_positions'][test_rec] : train_encodings_fast['end_positions'][test_rec]]\nprint(tokenizerFast.decode(predict_answer_tokens))\nprint(train_answers[test_rec]['text'])\nprint(tokenizerFast.decode(train_encodings_fast['input_ids'][test_rec]))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:09.361588Z","iopub.execute_input":"2024-03-06T16:16:09.361984Z","iopub.status.idle":"2024-03-06T16:16:09.379619Z","shell.execute_reply.started":"2024-03-06T16:16:09.361951Z","shell.execute_reply":"2024-03-06T16:16:09.378610Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"68\n71\nsinging and dancing\nsinging and dancing\n[CLS] what areas did beyonce compete in when she was growing up? [SEP] beyonce giselle knowles - carter ( / biːˈjɒnseɪ / bee - yon - say ) ( born september 4, 1981 ) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r & b girl - group destiny's child. managed by her father, mathew knowles, the group became one of the world's best - selling girl groups of all time. their hiatus saw the release of beyonce's debut album, dangerously in love ( 2003 ), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \". [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","output_type":"stream"}]},{"cell_type":"code","source":"def ret_Answer_start_and_end_valid(idx):\n    ret_start = 0\n    ret_end = 0\n    answer_encoding_fast = tokenizerFast(valid_answers[idx]['text'],  max_length = MAX_LENGTH, truncation=True, padding=True)\n    for a in range( len(valid_encodings_fast['input_ids'][idx])  -  len(answer_encoding_fast['input_ids'])   ): #len(train_encodings_fast['input_ids'][0])):\n        match = True\n        for i in range(1,len(answer_encoding_fast['input_ids']) - 1):\n            if (answer_encoding_fast['input_ids'][i] != valid_encodings_fast['input_ids'][idx][a + i]):\n                match = False\n                break\n        if match:\n            ret_start = a+1\n            ret_end = a+i+1\n            break\n    return(ret_start, ret_end)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:09.380703Z","iopub.execute_input":"2024-03-06T16:16:09.381008Z","iopub.status.idle":"2024-03-06T16:16:09.391616Z","shell.execute_reply.started":"2024-03-06T16:16:09.380983Z","shell.execute_reply":"2024-03-06T16:16:09.390551Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"start_positions = []\nend_positions = []\nctr = 0\nfor h in range(len(valid_encodings_fast['input_ids']) ):\n    #print(h)\n    s, e = ret_Answer_start_and_end_valid(h)\n    start_positions.append(s)\n    end_positions.append(e)\n    if s==0:\n        ctr = ctr + 1\n\n    \nvalid_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})\nprint(ctr)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:09.392750Z","iopub.execute_input":"2024-03-06T16:16:09.393071Z","iopub.status.idle":"2024-03-06T16:16:15.206690Z","shell.execute_reply.started":"2024-03-06T16:16:09.393043Z","shell.execute_reply":"2024-03-06T16:16:15.205387Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"393\n","output_type":"stream"}]},{"cell_type":"code","source":"test_rec=2\n\nz,x = ret_Answer_start_and_end_valid(test_rec)\n\npredict_answer_tokens = valid_encodings_fast.input_ids[test_rec][z : x]\nprint(tokenizerFast.decode(predict_answer_tokens))\nprint(valid_answers[test_rec]['text'])\nprint(tokenizerFast.decode(valid_encodings_fast['input_ids'][test_rec]))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.208072Z","iopub.execute_input":"2024-03-06T16:16:15.208376Z","iopub.status.idle":"2024-03-06T16:16:15.218976Z","shell.execute_reply.started":"2024-03-06T16:16:15.208350Z","shell.execute_reply":"2024-03-06T16:16:15.217978Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"france\nfrance\n[CLS] in what country is normandy located? [SEP] the normans ( norman : nourmands ; french : normands ; latin : normanni ) were the people who in the 10th and 11th centuries gave their name to normandy, a region in france. they were descended from norse ( \" norman \" comes from \" norseman \" ) raiders and pirates from denmark, iceland and norway who, under their leader rollo, agreed to swear fealty to king charles iii of west francia. through generations of assimilation and mixing with the native frankish and roman - gaulish populations, their descendants would gradually merge with the carolingian - based cultures of west francia. the distinct cultural and ethnic identity of the normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_encodings_fast.keys())\nprint(valid_encodings_fast.keys())\nprint(len(train_encodings_fast['input_ids']))\nprint(len(train_encodings_fast['start_positions']))\nprint(len(train_encodings_fast['end_positions']))\nprint(len(valid_encodings_fast['input_ids']))\nprint(len(valid_encodings_fast['start_positions']))\nprint(len(valid_encodings_fast['end_positions']))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.220372Z","iopub.execute_input":"2024-03-06T16:16:15.220741Z","iopub.status.idle":"2024-03-06T16:16:15.238983Z","shell.execute_reply.started":"2024-03-06T16:16:15.220714Z","shell.execute_reply":"2024-03-06T16:16:15.237972Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n86821\n86821\n86821\n20302\n20302\n20302\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizerFast.decode(train_encodings_fast['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.240186Z","iopub.execute_input":"2024-03-06T16:16:15.240526Z","iopub.status.idle":"2024-03-06T16:16:15.254772Z","shell.execute_reply.started":"2024-03-06T16:16:15.240498Z","shell.execute_reply":"2024-03-06T16:16:15.253811Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"'[CLS] when did beyonce start becoming popular? [SEP] beyonce giselle knowles - carter ( / biːˈjɒnseɪ / bee - yon - say ) ( born september 4, 1981 ) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r & b girl - group destiny\\'s child. managed by her father, mathew knowles, the group became one of the world\\'s best - selling girl groups of all time. their hiatus saw the release of beyonce\\'s debut album, dangerously in love ( 2003 ), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \". [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizerFast.decode(train_encodings_fast['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.256047Z","iopub.execute_input":"2024-03-06T16:16:15.256361Z","iopub.status.idle":"2024-03-06T16:16:15.273384Z","shell.execute_reply.started":"2024-03-06T16:16:15.256336Z","shell.execute_reply":"2024-03-06T16:16:15.272515Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"'[CLS] when did beyonce start becoming popular? [SEP] beyonce giselle knowles - carter ( / biːˈjɒnseɪ / bee - yon - say ) ( born september 4, 1981 ) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r & b girl - group destiny\\'s child. managed by her father, mathew knowles, the group became one of the world\\'s best - selling girl groups of all time. their hiatus saw the release of beyonce\\'s debut album, dangerously in love ( 2003 ), which established her as a solo artist worldwide, earned five grammy awards and featured the billboard hot 100 number - one singles \" crazy in love \" and \" baby boy \". [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"},"metadata":{}}]},{"cell_type":"code","source":"test_row= 0\nprint(train_contexts[test_row][train_answers[test_row]['answer_start']:train_answers[test_row]['answer_end']])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.274726Z","iopub.execute_input":"2024-03-06T16:16:15.275504Z","iopub.status.idle":"2024-03-06T16:16:15.283009Z","shell.execute_reply.started":"2024-03-06T16:16:15.275467Z","shell.execute_reply":"2024-03-06T16:16:15.282027Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"in the late 1990s\n","output_type":"stream"}]},{"cell_type":"code","source":"\nanswer_start_index = 75\nanswer_end_index = 79\n\npredict_answer_tokens = train_encodings_fast.input_ids[0][answer_start_index : answer_end_index]\ntokenizerFast.decode(predict_answer_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.284287Z","iopub.execute_input":"2024-03-06T16:16:15.284970Z","iopub.status.idle":"2024-03-06T16:16:15.296441Z","shell.execute_reply.started":"2024-03-06T16:16:15.284943Z","shell.execute_reply":"2024-03-06T16:16:15.295452Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"'in the late 1990s'"},"metadata":{}}]},{"cell_type":"code","source":"class InputDataset(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n    def __getitem__(self, i):\n        return {\n            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n        }\n    def __len__(self):\n        return len(self.encodings['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.297684Z","iopub.execute_input":"2024-03-06T16:16:15.298007Z","iopub.status.idle":"2024-03-06T16:16:15.310859Z","shell.execute_reply.started":"2024-03-06T16:16:15.297976Z","shell.execute_reply":"2024-03-06T16:16:15.309959Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"train_dataset = InputDataset(train_encodings_fast)\nvalid_dataset = InputDataset(valid_encodings_fast)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.311918Z","iopub.execute_input":"2024-03-06T16:16:15.312238Z","iopub.status.idle":"2024-03-06T16:16:15.321973Z","shell.execute_reply.started":"2024-03-06T16:16:15.312214Z","shell.execute_reply":"2024-03-06T16:16:15.321162Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset))\nprint(train_dataset[0].keys())","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.323223Z","iopub.execute_input":"2024-03-06T16:16:15.323673Z","iopub.status.idle":"2024-03-06T16:16:15.334519Z","shell.execute_reply.started":"2024-03-06T16:16:15.323638Z","shell.execute_reply":"2024-03-06T16:16:15.333624Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"86821\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_dataset[0].keys())","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.335768Z","iopub.execute_input":"2024-03-06T16:16:15.336154Z","iopub.status.idle":"2024-03-06T16:16:15.346437Z","shell.execute_reply.started":"2024-03-06T16:16:15.336119Z","shell.execute_reply":"2024-03-06T16:16:15.345430Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nvalid_data_loader = DataLoader(valid_dataset, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:15.347734Z","iopub.execute_input":"2024-03-06T16:16:15.348084Z","iopub.status.idle":"2024-03-06T16:16:18.992358Z","shell.execute_reply.started":"2024-03-06T16:16:15.348055Z","shell.execute_reply":"2024-03-06T16:16:18.991089Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# model = BertForQuestionAnswering.from_pretrained(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:18.994290Z","iopub.execute_input":"2024-03-06T16:16:18.994750Z","iopub.status.idle":"2024-03-06T16:16:19.006672Z","shell.execute_reply.started":"2024-03-06T16:16:18.994709Z","shell.execute_reply":"2024-03-06T16:16:19.005662Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"\nMODEL_PATH = \"bert-base-uncased\"\nbert_model = BertModel.from_pretrained(MODEL_PATH)  \n# MODEL_PATH = \"bert-base-uncased\"\n# bert_model.load_state_dict(torch.load('/kaggle/working/modelekKKKKKKKKKKKKKKKK.pt'))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.007834Z","iopub.execute_input":"2024-03-06T16:16:19.008729Z","iopub.status.idle":"2024-03-06T16:16:19.315051Z","shell.execute_reply.started":"2024-03-06T16:16:19.008700Z","shell.execute_reply":"2024-03-06T16:16:19.314145Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# MODEL_PATH = model.load_state_dict(torch.load('/kaggle/working/modelekKKKKKKKKKKKKKKKK.pt'))\n# bert_model = BertModel.from_pretrained(MODEL_PATH)  #MODEL_PATH = \"bert-base-uncased\"\n# TUTAJ KURWA WAGI WPIERDALASZ TORCH KURWA LOAD, ROZUMIESZ TO???\nclass QAModel(nn.Module):\n    def __init__(self):\n        super(QAModel, self).__init__()\n        self.bert = bert_model\n        self.drop_out = nn.Dropout(0.1)\n        self.l1 = nn.Linear(768 * 2, 768 * 2)\n        self.l2 = nn.Linear(768 * 2, 2)\n        self.linear_relu_stack = nn.Sequential(\n            self.drop_out,\n            self.l1,\n            nn.LeakyReLU(),\n            self.l2 \n        )\n        \n    def forward(self, input_ids, attention_mask, token_type_ids):\n        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n        hidden_states = model_output[2]\n        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)  # taking Start logits from last BERT layer, End Logits from third to last layer\n        logits = self.linear_relu_stack(out)\n        \n        start_logits, end_logits = logits.split(1, dim=-1)\n        \n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n\n        return start_logits, end_logits","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.316469Z","iopub.execute_input":"2024-03-06T16:16:19.316793Z","iopub.status.idle":"2024-03-06T16:16:19.326532Z","shell.execute_reply.started":"2024-03-06T16:16:19.316766Z","shell.execute_reply":"2024-03-06T16:16:19.325535Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"model = QAModel()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.327891Z","iopub.execute_input":"2024-03-06T16:16:19.328229Z","iopub.status.idle":"2024-03-06T16:16:19.364464Z","shell.execute_reply.started":"2024-03-06T16:16:19.328202Z","shell.execute_reply":"2024-03-06T16:16:19.363663Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/input/wagi-06-03-2024/modelekKKKKKKKKKKKKKKKK.pt'))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.365496Z","iopub.execute_input":"2024-03-06T16:16:19.365802Z","iopub.status.idle":"2024-03-06T16:16:19.370092Z","shell.execute_reply.started":"2024-03-06T16:16:19.365777Z","shell.execute_reply":"2024-03-06T16:16:19.369047Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.371301Z","iopub.execute_input":"2024-03-06T16:16:19.371579Z","iopub.status.idle":"2024-03-06T16:16:19.381386Z","shell.execute_reply.started":"2024-03-06T16:16:19.371555Z","shell.execute_reply":"2024-03-06T16:16:19.380246Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# my function to manually calculate Cross Entropy Loss\ndef loss_fn(start_logits, end_logits, start_positions, end_positions):\n    loss_fct = nn.CrossEntropyLoss()\n    start_loss = loss_fct(start_logits, start_positions)\n    end_loss = loss_fct(end_logits, end_positions)\n    total_loss = (start_loss + end_loss)/2\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.382819Z","iopub.execute_input":"2024-03-06T16:16:19.383192Z","iopub.status.idle":"2024-03-06T16:16:19.392812Z","shell.execute_reply.started":"2024-03-06T16:16:19.383158Z","shell.execute_reply":"2024-03-06T16:16:19.391884Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# my focal loss function. Focal Loss = (True Vector)*((1 - probs)^Gamma)*log(probs)\n# where Gamma is a factor we use. setting Gamma = 0 makes this a Cross Entropy Loss function\n\ndef focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n    \n    #calculate Probabilities by applying Softmax to the Start and End Logits. Then get 1 - probabilities\n    smax = nn.Softmax(dim=1)\n    probs_start = smax(start_logits)\n    inv_probs_start = 1 - probs_start\n    probs_end = smax(end_logits)\n    inv_probs_end = 1 - probs_end\n    \n    #get log of probabilities. Note: NLLLoss required log probabilities. This is the Natural Log (Log base e)\n    lsmax = nn.LogSoftmax(dim=1)\n    log_probs_start = lsmax(start_logits)\n    log_probs_end = lsmax(end_logits)\n    \n    nll = nn.NLLLoss()\n    \n    fl_start = nll(torch.pow(inv_probs_start, gamma)* log_probs_start, start_positions)\n    fl_end = nll(torch.pow(inv_probs_end, gamma)*log_probs_end, end_positions)\n    \n    #return mean of the Loss for the start and end logits\n    return ((fl_start + fl_end)/2)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.394028Z","iopub.execute_input":"2024-03-06T16:16:19.394381Z","iopub.status.idle":"2024-03-06T16:16:19.404963Z","shell.execute_reply.started":"2024-03-06T16:16:19.394350Z","shell.execute_reply":"2024-03-06T16:16:19.404180Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\nscheduler = ExponentialLR(optim, gamma=0.9)\ntotal_acc = []\ntotal_loss = []","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.406004Z","iopub.execute_input":"2024-03-06T16:16:19.406286Z","iopub.status.idle":"2024-03-06T16:16:19.425474Z","shell.execute_reply.started":"2024-03-06T16:16:19.406261Z","shell.execute_reply":"2024-03-06T16:16:19.424444Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, dataloader, epoch):\n    model = model.train()\n    losses = []\n    acc = []\n    ctr = 0\n    batch_tracker = 0\n    for batch in tqdm(dataloader, desc = 'Running Epoch '):\n        optim.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        token_type_ids = batch['token_type_ids'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        out_start, out_end = model(input_ids=input_ids, \n                attention_mask=attention_mask,\n                token_type_ids=token_type_ids)\n        #loss = loss_fn(out_start, out_end, start_positions, end_positions)  # <---BASELINE.  Cross Entropy Loss is returned by Default\n        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions,1) #using gamma = 1\n        losses.append(loss.item())\n        loss.backward()\n        optim.step()\n        \n        start_pred = torch.argmax(out_start, dim=1)\n        end_pred = torch.argmax(out_end, dim=1)\n            \n        acc.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n        acc.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n        #ctr = ctr +1\n        #if ctr==50:\n        #    break\n        batch_tracker = batch_tracker + 1\n        if batch_tracker==250 and epoch==1:\n            total_acc.append(sum(acc)/len(acc))\n            loss_avg = sum(losses)/len(losses)\n            total_loss.append(loss_avg)\n            batch_tracker = 0\n            torch.save(model.state_dict(), \"./modelekKKKKKKKKKKKKKKKK.pt\")\n    scheduler.step()\n    ret_acc = sum(acc)/len(acc)\n    ret_loss = sum(losses)/len(losses)\n    return(ret_acc, ret_loss)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.427023Z","iopub.execute_input":"2024-03-06T16:16:19.427315Z","iopub.status.idle":"2024-03-06T16:16:19.439846Z","shell.execute_reply.started":"2024-03-06T16:16:19.427290Z","shell.execute_reply":"2024-03-06T16:16:19.438849Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, dataloader):\n    model = model.eval()\n    losses = []\n    acc = []\n    ctr = 0\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc = 'Running Evaluation'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            start_true = batch['start_positions'].to(device)\n            end_true = batch['end_positions'].to(device)\n            \n            out_start, out_end = model(input_ids=input_ids, \n                attention_mask=attention_mask,\n                token_type_ids=token_type_ids)\n            \n            start_pred = torch.argmax(out_start, dim=1)\n            end_pred = torch.argmax(out_end, dim=1)\n            \n            acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n            acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n            #ctr = ctr +1\n            #if ctr==50:\n            #    break\n        ret_acc = sum(acc)/len(acc)\n        ret_loss = 0\n        #ret_loss = sum(losses)/len(losses)\n    return(ret_acc)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.441255Z","iopub.execute_input":"2024-03-06T16:16:19.441919Z","iopub.status.idle":"2024-03-06T16:16:19.455410Z","shell.execute_reply.started":"2024-03-06T16:16:19.441883Z","shell.execute_reply":"2024-03-06T16:16:19.454506Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.456845Z","iopub.execute_input":"2024-03-06T16:16:19.457981Z","iopub.status.idle":"2024-03-06T16:16:19.618342Z","shell.execute_reply.started":"2024-03-06T16:16:19.457944Z","shell.execute_reply":"2024-03-06T16:16:19.617160Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\nprint(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\nprint(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.620059Z","iopub.execute_input":"2024-03-06T16:16:19.620442Z","iopub.status.idle":"2024-03-06T16:16:19.631608Z","shell.execute_reply.started":"2024-03-06T16:16:19.620405Z","shell.execute_reply":"2024-03-06T16:16:19.630693Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"torch.cuda.memory_allocated: 0.016022GB\ntorch.cuda.memory_reserved: 0.039062GB\ntorch.cuda.max_memory_reserved: 3.513672GB\n","output_type":"stream"}]},{"cell_type":"code","source":"EPOCHS = 1\n\nmodel.to(device)\n\nfor epoch in range(EPOCHS):\n    train_acc, train_loss = train_epoch(model, train_data_loader, epoch+1)\n    print(f\"Train Accuracy: {train_acc}      Train Loss: {train_loss}\")\n    val_acc = eval_model(model, valid_data_loader)\n    print(f\"Validation Accuracy: {val_acc}\")\n    \n# val_acc, val_loss = eval_model(model, valid_data_loader)\n# print(f\"Validation Accuracy: {val_acc}   Validation Loss: {val_loss}\")\n  ","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:16:19.632863Z","iopub.execute_input":"2024-03-06T16:16:19.633183Z","iopub.status.idle":"2024-03-06T16:58:20.144945Z","shell.execute_reply.started":"2024-03-06T16:16:19.633158Z","shell.execute_reply":"2024-03-06T16:58:20.143891Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stderr","text":"Running Epoch : 100%|██████████| 10853/10853 [39:17<00:00,  4.60it/s] \n","output_type":"stream"},{"name":"stdout","text":"Train Accuracy: 0.6175435363510441      Train Loss: 1.1568920159719127\n","output_type":"stream"},{"name":"stderr","text":"Running Evaluation: 100%|██████████| 1269/1269 [02:43<00:00,  7.78it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.6515887087758504\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"x = next(iter(train_data_loader))\n\nn = 1\nctx_i = tokenizerFast.decode(x['input_ids'][n]).split()\nctx_t = tokenizerFast.decode(x['token_type_ids'][n]).split()\n\nfor i in range(0,len(ctx_i),10):\n    s=''\n    for j in ctx_i[i:i+10]:\n        s+=j+' '\n    print(s)\n\nctx_i[x['start_positions'][n]:x['end_positions'][n]+1]","metadata":{"execution":{"iopub.status.busy":"2024-03-06T16:58:20.146236Z","iopub.execute_input":"2024-03-06T16:58:20.146517Z","iopub.status.idle":"2024-03-06T16:58:20.173813Z","shell.execute_reply.started":"2024-03-06T16:58:20.146492Z","shell.execute_reply":"2024-03-06T16:58:20.172781Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"[CLS] how many of ibn sina's shorter works were said \nto have been created in rey? [SEP] ibn sina subsequently \nsettled at rey, in the vicinity of modern tehran, the \nhome town of rhazes ; where majd addaula, a son \nof the last buwayhid emir, was nominal ruler under the \nregency of his mother ( seyyedeh khatun ). about thirty \nof ibn sina's shorter works are said to have been \ncomposed in rey. constant feuds which raged between the regent \nand her second son, shams al - daula, however, compelled \nthe scholar to quit the place. after a brief sojourn \nat qazvin he passed southwards to hamadan where shams al \n- daula, another buwayhid emir, had established himself. at first, \nibn sina entered into the service of a high - \nborn lady ; but the emir, hearing of his arrival, \ncalled him in as medical attendant, and sent him back \nwith presents to his dwelling. ibn sina was even raised \nto the office of vizier. the emir decreed that he \nshould be banished from the country. ibn sina, however, remained \nhidden for forty days in sheikh ahmed fadhel [SEP] \n","output_type":"stream"},{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"['her', 'second']"},"metadata":{}}]}]}